{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'nlp' extra dependecy package 'gensim' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "'nlp' extra dependecy package 'nltk' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "'nlp' extra dependecy package 'transformers' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "'nlp' extra dependecy package 'gensim' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "'nlp' extra dependecy package 'nltk' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "'nlp' extra dependecy package 'transformers' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhenghao/.conda/envs/light_new/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/zhenghao/.conda/envs/light_new/lib/python3.9/site-packages/lightautoml/ml_algo/dl_model.py:42: UserWarning: 'transformers' - package isn't installed\n",
      "  warnings.warn(\"'transformers' - package isn't installed\")\n",
      "/home/zhenghao/.conda/envs/light_new/lib/python3.9/site-packages/lightautoml/text/embed.py:22: UserWarning: 'transformers' - package isn't installed\n",
      "  warnings.warn(\"'transformers' - package isn't installed\")\n",
      "/home/zhenghao/.conda/envs/light_new/lib/python3.9/site-packages/lightautoml/text/dl_transformers.py:25: UserWarning: 'transformers' - package isn't installed\n",
      "  warnings.warn(\"'transformers' - package isn't installed\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# LightAutoML presets, task and report generation\n",
    "from lightautoml.automl.presets.tabular_presets import TabularAutoML\n",
    "from lightautoml.tasks import Task\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/home/zhenghao/kaggle/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val = train_test_split(train, test_size=0.2, random_state=42, shuffle=True, stratify=train.Response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = Task('binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:10:26] Stdout logging level is DEBUG.\n",
      "[17:10:26] Copying TaskTimer may affect the parent PipelineTimer, so copy will create new unlimited TaskTimer\n",
      "[17:10:26] Task: binary\n",
      "\n",
      "[17:10:26] Start automl preset with listed constraints:\n",
      "[17:10:26] - time: 2160000.00 seconds\n",
      "[17:10:26] - CPU: 24 cores\n",
      "[17:10:26] - memory: 16 GB\n",
      "\n",
      "[17:10:26] \u001b[1mTrain data shape: (9203838, 12)\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhenghao/.conda/envs/light_new/lib/python3.9/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:10:39] Feats was rejected during automatic roles guess: []\n",
      "[17:10:40] Layer \u001b[1m1\u001b[0m train process start. Time left 2159985.92 secs\n",
      "[17:18:27] Linear model: C = 1e-05 score = 0.8728472677415857\n",
      "[17:21:11] Linear model: C = 5e-05 score = 0.8742297510889349\n",
      "[17:21:22] Linear model: C = 0.0001 score = 0.8742298760575264\n",
      "[17:24:58] Linear model: C = 0.0005 score = 0.8746943820109827\n",
      "[17:25:02] Linear model: C = 0.001 score = 0.8746943820109827\n",
      "[17:25:06] Linear model: C = 0.005 score = 0.8746943820109827\n",
      "[17:25:07] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[17:25:07] Time left 2159119.22 secs\n",
      "\n",
      "[17:25:13] Training until validation scores don't improve for 100 rounds\n",
      "[17:25:34] [100]\tvalid's auc: 0.878627\n",
      "[17:25:55] [200]\tvalid's auc: 0.88\n",
      "[17:26:15] [300]\tvalid's auc: 0.880321\n",
      "[17:26:34] [400]\tvalid's auc: 0.88049\n",
      "[17:26:53] [500]\tvalid's auc: 0.880594\n",
      "[17:27:12] [600]\tvalid's auc: 0.880683\n",
      "[17:27:30] [700]\tvalid's auc: 0.880743\n",
      "[17:27:48] [800]\tvalid's auc: 0.880772\n",
      "[17:28:06] [900]\tvalid's auc: 0.8808\n",
      "[17:28:24] [1000]\tvalid's auc: 0.880809\n",
      "[17:28:42] [1100]\tvalid's auc: 0.880816\n",
      "[17:28:59] [1200]\tvalid's auc: 0.880799\n",
      "[17:28:59] Early stopping, best iteration is:\n",
      "[1100]\tvalid's auc: 0.880816\n",
      "[17:29:15] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[17:34:42] Training until validation scores don't improve for 100 rounds\n",
      "[17:35:08] [100]\tvalid's auc: 0.884563\n",
      "[17:35:32] [200]\tvalid's auc: 0.885295\n",
      "[17:35:51] Early stopping, best iteration is:\n",
      "[189]\tvalid's auc: 0.885345\n",
      "[17:35:53] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[17:35:53] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 300.00 secs\n",
      "[17:35:56] Training until validation scores don't improve for 100 rounds\n",
      "[17:36:20] [100]\tvalid's auc: 0.884531\n",
      "[17:36:45] [200]\tvalid's auc: 0.885462\n",
      "[17:37:07] [300]\tvalid's auc: 0.885582\n",
      "[17:37:27] [400]\tvalid's auc: 0.885639\n",
      "[17:37:46] [500]\tvalid's auc: 0.885721\n",
      "[17:38:06] [600]\tvalid's auc: 0.88574\n",
      "[17:38:25] [700]\tvalid's auc: 0.885761\n",
      "[17:38:45] [800]\tvalid's auc: 0.885772\n",
      "[17:39:03] [900]\tvalid's auc: 0.885777\n",
      "[17:39:16] Early stopping, best iteration is:\n",
      "[869]\tvalid's auc: 0.885786\n",
      "[17:39:28] \u001b[1mTrial 1\u001b[0m with hyperparameters {'feature_fraction': 0.6872700594236812, 'num_leaves': 244, 'bagging_fraction': 0.8659969709057025, 'min_sum_hessian_in_leaf': 0.24810409748678125, 'reg_alpha': 2.5361081166471375e-07, 'reg_lambda': 2.5348407664333426e-07} scored 0.8857855542773424 in 0:03:35.059139\n",
      "[17:39:31] Training until validation scores don't improve for 100 rounds\n",
      "[17:39:54] [100]\tvalid's auc: 0.884297\n",
      "[17:40:17] [200]\tvalid's auc: 0.885474\n",
      "[17:40:39] [300]\tvalid's auc: 0.885698\n",
      "[17:40:59] [400]\tvalid's auc: 0.885791\n",
      "[17:41:19] [500]\tvalid's auc: 0.885869\n",
      "[17:41:39] [600]\tvalid's auc: 0.885887\n",
      "[17:41:58] [700]\tvalid's auc: 0.885931\n",
      "[17:42:17] [800]\tvalid's auc: 0.88593\n",
      "[17:42:37] [900]\tvalid's auc: 0.885959\n",
      "[17:42:56] [1000]\tvalid's auc: 0.885976\n",
      "[17:43:15] [1100]\tvalid's auc: 0.885983\n",
      "[17:43:34] [1200]\tvalid's auc: 0.885987\n",
      "[17:43:53] [1300]\tvalid's auc: 0.88599\n",
      "[17:43:55] Early stopping, best iteration is:\n",
      "[1214]\tvalid's auc: 0.885993\n",
      "[17:44:14] \u001b[1mTrial 2\u001b[0m with hyperparameters {'feature_fraction': 0.5290418060840998, 'num_leaves': 223, 'bagging_fraction': 0.8005575058716043, 'min_sum_hessian_in_leaf': 0.679657809075816, 'reg_alpha': 1.5320059381854043e-08, 'reg_lambda': 5.360294728728285} scored 0.8859931437232651 in 0:04:45.271670\n",
      "[17:44:14] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[17:44:14] The set of hyperparameters \u001b[1m{'feature_fraction': 0.5290418060840998, 'num_leaves': 223, 'bagging_fraction': 0.8005575058716043, 'min_sum_hessian_in_leaf': 0.679657809075816, 'reg_alpha': 1.5320059381854043e-08, 'reg_lambda': 5.360294728728285}\u001b[0m\n",
      " achieve 0.8860 auc\n",
      "[17:44:16] Training until validation scores don't improve for 100 rounds\n",
      "[17:44:39] [100]\tvalid's auc: 0.884297\n",
      "[17:45:02] [200]\tvalid's auc: 0.885474\n",
      "[17:45:24] [300]\tvalid's auc: 0.885698\n",
      "[17:45:45] [400]\tvalid's auc: 0.885791\n",
      "[17:46:06] [500]\tvalid's auc: 0.885869\n",
      "[17:46:26] [600]\tvalid's auc: 0.885887\n",
      "[17:46:46] [700]\tvalid's auc: 0.885931\n",
      "[17:47:06] [800]\tvalid's auc: 0.88593\n",
      "[17:47:26] [900]\tvalid's auc: 0.885959\n",
      "[17:47:46] [1000]\tvalid's auc: 0.885976\n",
      "[17:48:05] [1100]\tvalid's auc: 0.885983\n",
      "[17:48:25] [1200]\tvalid's auc: 0.885987\n",
      "[17:48:45] [1300]\tvalid's auc: 0.88599\n",
      "[17:48:47] Early stopping, best iteration is:\n",
      "[1214]\tvalid's auc: 0.885993\n",
      "[17:49:08] Default metric period is 5 because AUC\n",
      "[17:49:08]  is/are not implemented for GPU\n",
      "[17:49:08] 0:\ttest: 0.8583151\tbest: 0.8583151 (0)\ttotal: 50.5ms\tremaining: 2m 31s\n",
      "[17:49:12] 100:\ttest: 0.8783525\tbest: 0.8783525 (100)\ttotal: 3.82s\tremaining: 1m 49s\n",
      "[17:49:16] 200:\ttest: 0.8803856\tbest: 0.8803856 (200)\ttotal: 7.61s\tremaining: 1m 45s\n",
      "[17:49:20] 300:\ttest: 0.8813081\tbest: 0.8813081 (300)\ttotal: 11.4s\tremaining: 1m 42s\n",
      "[17:49:24] 400:\ttest: 0.8818315\tbest: 0.8818315 (400)\ttotal: 15.2s\tremaining: 1m 38s\n",
      "[17:49:27] 500:\ttest: 0.8821635\tbest: 0.8821635 (500)\ttotal: 19.1s\tremaining: 1m 35s\n",
      "[17:49:31] 600:\ttest: 0.8824323\tbest: 0.8824323 (600)\ttotal: 23s\tremaining: 1m 31s\n",
      "[17:49:35] 700:\ttest: 0.8826225\tbest: 0.8826225 (700)\ttotal: 26.8s\tremaining: 1m 27s\n",
      "[17:49:39] 800:\ttest: 0.8827649\tbest: 0.8827649 (800)\ttotal: 30.7s\tremaining: 1m 24s\n",
      "[17:49:43] 900:\ttest: 0.8828916\tbest: 0.8828916 (900)\ttotal: 34.5s\tremaining: 1m 20s\n",
      "[17:49:47] 1000:\ttest: 0.8829989\tbest: 0.8829989 (1000)\ttotal: 38.4s\tremaining: 1m 16s\n",
      "[17:49:51] 1100:\ttest: 0.8830800\tbest: 0.8830800 (1100)\ttotal: 42.2s\tremaining: 1m 12s\n",
      "[17:49:54] 1200:\ttest: 0.8831639\tbest: 0.8831639 (1200)\ttotal: 46.1s\tremaining: 1m 9s\n",
      "[17:49:58] 1300:\ttest: 0.8832471\tbest: 0.8832471 (1300)\ttotal: 49.9s\tremaining: 1m 5s\n",
      "[17:50:02] 1400:\ttest: 0.8833190\tbest: 0.8833190 (1399)\ttotal: 53.7s\tremaining: 1m 1s\n",
      "[17:50:06] 1500:\ttest: 0.8833697\tbest: 0.8833697 (1500)\ttotal: 57.6s\tremaining: 57.5s\n",
      "[17:50:10] 1600:\ttest: 0.8834130\tbest: 0.8834130 (1600)\ttotal: 1m 1s\tremaining: 53.7s\n",
      "[17:50:14] 1700:\ttest: 0.8834564\tbest: 0.8834564 (1700)\ttotal: 1m 5s\tremaining: 49.9s\n",
      "[17:50:17] 1800:\ttest: 0.8834943\tbest: 0.8834943 (1800)\ttotal: 1m 9s\tremaining: 46s\n",
      "[17:50:21] 1900:\ttest: 0.8835305\tbest: 0.8835306 (1899)\ttotal: 1m 12s\tremaining: 42.2s\n",
      "[17:50:25] 2000:\ttest: 0.8835661\tbest: 0.8835661 (2000)\ttotal: 1m 16s\tremaining: 38.3s\n",
      "[17:50:29] 2100:\ttest: 0.8835956\tbest: 0.8835956 (2100)\ttotal: 1m 20s\tremaining: 34.5s\n",
      "[17:50:33] 2200:\ttest: 0.8836196\tbest: 0.8836196 (2197)\ttotal: 1m 24s\tremaining: 30.7s\n",
      "[17:50:37] 2300:\ttest: 0.8836491\tbest: 0.8836491 (2300)\ttotal: 1m 28s\tremaining: 26.8s\n",
      "[17:50:41] 2400:\ttest: 0.8836716\tbest: 0.8836716 (2400)\ttotal: 1m 32s\tremaining: 23s\n",
      "[17:50:44] 2500:\ttest: 0.8836875\tbest: 0.8836876 (2499)\ttotal: 1m 35s\tremaining: 19.1s\n",
      "[17:50:48] 2600:\ttest: 0.8837073\tbest: 0.8837073 (2600)\ttotal: 1m 39s\tremaining: 15.3s\n",
      "[17:50:52] 2700:\ttest: 0.8837312\tbest: 0.8837313 (2699)\ttotal: 1m 43s\tremaining: 11.5s\n",
      "[17:50:56] 2800:\ttest: 0.8837528\tbest: 0.8837528 (2800)\ttotal: 1m 47s\tremaining: 7.64s\n",
      "[17:51:00] 2900:\ttest: 0.8837702\tbest: 0.8837702 (2900)\ttotal: 1m 51s\tremaining: 3.8s\n",
      "[17:51:03] 2999:\ttest: 0.8837849\tbest: 0.8837849 (2998)\ttotal: 1m 55s\tremaining: 0us\n",
      "[17:51:04] bestTest = 0.8837849498\n",
      "[17:51:04] bestIteration = 2998\n",
      "[17:51:04] Shrink model to first 2999 iterations.\n",
      "[17:51:04] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[17:51:04] Time left 2157561.65 secs\n",
      "\n",
      "[17:51:04] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[17:51:05] Blending: optimization starts with equal weights and score \u001b[1m0.8847764078964679\u001b[0m\n",
      "[17:51:27] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.8859931437232651\u001b[0m, weights = \u001b[1m[0. 0. 1. 0.]\u001b[0m\n",
      "[17:51:49] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.886000674772374\u001b[0m, weights = \u001b[1m[0.        0.0956633 0.9043367 0.       ]\u001b[0m\n",
      "[17:52:10] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.886000674772374\u001b[0m, weights = \u001b[1m[0.        0.0956633 0.9043367 0.       ]\u001b[0m\n",
      "[17:52:10] Blending: no score update. Terminated\n",
      "\n",
      "[17:52:11] \u001b[1mAutoml preset training completed in 2504.75 seconds\u001b[0m\n",
      "\n",
      "[17:52:11] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.09566 * (1 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.90434 * (1 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "automl = TabularAutoML(\n",
    "    task=task,  # 指定任务类型\n",
    "    timeout=600 * 3600,  # 设定训练时间上限为600小时\n",
    "    cpu_limit=24,  # 使用的CPU核心数量限制为12\n",
    "    gpu_ids='0',  # 使用第一个GPU\n",
    "    general_params={\"use_algos\": [['linear_l2', 'lgb', 'lgb_tuned', 'cb']]},  # 让系统自动选择合适的算法\n",
    "    reader_params={'n_jobs': 12, 'cv': 5, 'random_state': 42, 'advanced_roles': True}  # 数据读取参数\n",
    ")\n",
    "\n",
    "out_of_fold_predictions = automl.fit_predict(\n",
    "    X_train, valid_data=X_val,  # 训练集和验证集\n",
    "    roles={\n",
    "        'target': 'Response',  # 目标列\n",
    "        'drop': ['id'],  # 丢弃的列\n",
    "    }, \n",
    "    verbose=4  # 显示详细的训练信息\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "527"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train, X_train, X_val\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('/home/zhenghao/kaggle/test.csv')\n",
    "ss = pd.read_csv('/home/zhenghao/kaggle/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11504798</td>\n",
       "      <td>0.004403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11504799</td>\n",
       "      <td>0.640371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11504800</td>\n",
       "      <td>0.239501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11504801</td>\n",
       "      <td>0.000070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11504802</td>\n",
       "      <td>0.305886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7669861</th>\n",
       "      <td>19174659</td>\n",
       "      <td>0.217761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7669862</th>\n",
       "      <td>19174660</td>\n",
       "      <td>0.000158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7669863</th>\n",
       "      <td>19174661</td>\n",
       "      <td>0.000202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7669864</th>\n",
       "      <td>19174662</td>\n",
       "      <td>0.566881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7669865</th>\n",
       "      <td>19174663</td>\n",
       "      <td>0.000058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7669866 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  Response\n",
       "0        11504798  0.004403\n",
       "1        11504799  0.640371\n",
       "2        11504800  0.239501\n",
       "3        11504801  0.000070\n",
       "4        11504802  0.305886\n",
       "...           ...       ...\n",
       "7669861  19174659  0.217761\n",
       "7669862  19174660  0.000158\n",
       "7669863  19174661  0.000202\n",
       "7669864  19174662  0.566881\n",
       "7669865  19174663  0.000058\n",
       "\n",
       "[7669866 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = automl.predict(test).data[:,  0]\n",
    "\n",
    "ss.Response = pred\n",
    "ss.to_csv('LightAutoML_2.csv', index=None)\n",
    "ss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "light_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
